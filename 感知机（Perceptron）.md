    感知机（Perceptron）是二分类的线性分类模型，其输入为样本特征向量，输出为样本分类，分类取值为+1或-1。感知机的学习（fit）过程是寻找空间中的超平面，从而将进行线性分类，通过找出其损失函数（L），利用梯度下降（Gradient Descend）算法将将损失函数最小化从而求得超平面参数，获得划分方法。感知机的预测过程（predict）是将样本特征向量输入模型中，通过计算并判断样本与超平面的位置进行分类。

​        感知机于1957年由Rosenblatt提出，是神经网络、支持向量机算法的基础。

#  模型和算法的数学定义

**感知机数学定义**：假设输入空间（特征空间）为$X \sube R^n​$,输出空间为$Y \sube \{\pm1\}​$,输入$x \in X​$为输入样本实例的特征向量，对于输入空间（样本空间）的点，输出$ y \in Y​$表示其实例类别。输入空间到输出空间的关系由以下函数表示：
$$
y = f(x) = sign(w^Tx+b)
$$
这就是感知机的数学定义。其中，$w^T,b$为感知机模型的参数，可以通过梯度下降算法计算损失函数极小值从而求得，$w^T\in R^n$称为权值或权值向量（weight or weigjht vector），$b \in R$称为偏置（bias），$w^Tx$表示$w,x$的内积，sign是负号函数，即
$$
sign(x) = 
\begin{cases}
	+1 &\ x\eqslantgtr 0 \\
	-1 &\ x<0
\end{cases}
$$

感知机有如下集合解释：线性方程$w^Tx +b =0​$对应与特征空间$R^n​$的一个超平面S，其中w是超平面的法向量，b是超平面的截距。这个超平面将特征空间分为两个部分。


#  算法

简而言之，感知机算法就是构造损失函数$Loss(w^T,b)$,并通过梯度下降方法，求得模型参数$w^T,b$,这样感知机就确认。

##  构造损失函数

构造损失函数的一个方式是所有误分类点的总数，但这种损失函数的输出结果是离散的，不连续，对w和b也不可导。所以可以计算所有误分类点到超平面S的距离，这是感知机所采用的。

输入空间$R^n$任一点$x_0$到超平面S的距离为：
$$
\frac{1}{||w||}|w^Tx_0+b|
$$
其中$||w||$是$L_2$的范数。

对于误分类数据$(x_i,y_i)$来说，$|y_i|=1$，且$wx_i+b$与$y_i$符号相反，所以有
$$
|w^Tx_i+b|=-y_i(w^Tx_i+b)>0
$$
因此所有误分类点到超平面的距离S为：
$$
-\frac{y_i(w^Tx_i+b)}{||w||}
$$
假设所有误分类点的集合为M，则所有误分类点到超平面S的距离为：
$$
\sum_{x_i \in M}{-\frac{y_i(w^Tx_i+b)}{||w||}}
=-\frac{1}{||w||}\sum_{x_i\in M}{y_i(w^Tx_i+b)}
$$
不考虑$||w||$,就得到感知机学习的损失函数：
$$
L(w,b) = -\sum_{x_i \in M}{y_i(w^Tw_i+b)}
$$
显然，该损失函数是非负、连续的，且关于w，b可导。当所有点分类正确是，函数L为零。

